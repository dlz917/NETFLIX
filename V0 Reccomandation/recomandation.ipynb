{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systeme de Recommandation V0\n",
    "# Version 1 User\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recuperer la requete de filtrage et lutilsateur\n",
    "import sys\n",
    "user=sys.argv[1]\n",
    "requete=sys.argv[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\joans\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\joans\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\joans\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\joans\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    filtered_tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Lemmatize tokens\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    \n",
    "    # Stem tokens\n",
    "    stemmed_tokens = [stemmer.stem(token) for token in lemmatized_tokens]\n",
    "    \n",
    "    # Join the tokens back into a string\n",
    "    preprocessed_text = ' '.join(stemmed_tokens)\n",
    "    \n",
    "    return preprocessed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour recuperer la listes des films faut avant recuperer tous les participants de la salle (liste de id de utilisateurs)\n",
    "historique = \"select id_show from regarder where id_us = \" + str(user) + \";\"\n",
    "\n",
    "#recuperer la liste des films dans l'historique de l'utilisateur1(liste de id)\n",
    "#recuperer la liste des films dans l'historique de l'utilisateur2(liste de id)\n",
    "#recuperer la liste des films dans l'historique de l'utilisateur3(liste de id)\n",
    "#recuperer la liste des films dans l'historique de l'utilisateur4(liste de id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymysql.connections.Connection object at 0x00000245A571DA90>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "# Some other example server values are\n",
    "# server = 'localhost\\sqlexpress' # for a named instance\n",
    "# server = 'myserver,port' # to specify an alternate port\n",
    "cnxn = pymysql.connect(user=\"nchoice\", password=\"jenesaispas\", host=\"localhost\", database=\"nchoice\")\n",
    "\n",
    "print(cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joans\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#t = historique['id_show'].tolist()\n",
    "t=(\"s3\",\"s8\",\"s10\") #TEST\n",
    "requete_historique = \"SELECT show_new.*, GROUP_CONCAT(DISTINCT jouer.id_cast SEPARATOR ',') as cast_ids, GROUP_CONCAT(DISTINCT produire.id_direc SEPARATOR ',') as director_ids,GROUP_CONCAT(DISTINCT etre.id_genre SEPARATOR ',') as genre_ids FROM show_new LEFT JOIN jouer ON jouer.id_show = show_new.id_show LEFT JOIN produire ON produire.id_show = show_new.id_show LEFT JOIN etre ON etre.id_show = show_new.id_show  WHERE show_new.id_show IN {} GROUP BY show_new.id_show; \".format(t)\n",
    "\n",
    "films_historiques = pd.read_sql(requete_historique, cnxn)\n",
    "#films_filtres = pd.read_sql(requete, cnxn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_show</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>duration</th>\n",
       "      <th>description</th>\n",
       "      <th>cast_ids</th>\n",
       "      <th>director_ids</th>\n",
       "      <th>genre_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s10</td>\n",
       "      <td>Movie</td>\n",
       "      <td>The Starling</td>\n",
       "      <td>United States</td>\n",
       "      <td>2021</td>\n",
       "      <td>104 min</td>\n",
       "      <td>A woman adjusting to life after a loss contend...</td>\n",
       "      <td>c1515,c177,c21968,c24479,c29900,c33466,c3696,c...</td>\n",
       "      <td>d7</td>\n",
       "      <td>g7,g9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s3</td>\n",
       "      <td>TV Show</td>\n",
       "      <td>Ganglands</td>\n",
       "      <td></td>\n",
       "      <td>2021</td>\n",
       "      <td>1 Season</td>\n",
       "      <td>To protect his family from a powerful drug lor...</td>\n",
       "      <td>c12496,c13503,c14756,c15099,c2,c24222,c27258,c...</td>\n",
       "      <td>d2</td>\n",
       "      <td>g2,g22,g3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s8</td>\n",
       "      <td>Movie</td>\n",
       "      <td>Sankofa</td>\n",
       "      <td>United States, Ghana, Burkina Faso, United Kin...</td>\n",
       "      <td>1993</td>\n",
       "      <td>125 min</td>\n",
       "      <td>On a photo shoot in Ghana, an American model s...</td>\n",
       "      <td>c13505,c17323,c20918,c24225,c27259,c5399,c6,c9584</td>\n",
       "      <td>d5</td>\n",
       "      <td>g17,g29,g7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_show     type         title  \\\n",
       "0     s10    Movie  The Starling   \n",
       "1      s3  TV Show     Ganglands   \n",
       "2      s8    Movie       Sankofa   \n",
       "\n",
       "                                             country  year  duration  \\\n",
       "0                                      United States  2021   104 min   \n",
       "1                                                     2021  1 Season   \n",
       "2  United States, Ghana, Burkina Faso, United Kin...  1993   125 min   \n",
       "\n",
       "                                         description  \\\n",
       "0  A woman adjusting to life after a loss contend...   \n",
       "1  To protect his family from a powerful drug lor...   \n",
       "2  On a photo shoot in Ghana, an American model s...   \n",
       "\n",
       "                                            cast_ids director_ids   genre_ids  \n",
       "0  c1515,c177,c21968,c24479,c29900,c33466,c3696,c...           d7       g7,g9  \n",
       "1  c12496,c13503,c14756,c15099,c2,c24222,c27258,c...           d2   g2,g22,g3  \n",
       "2  c13505,c17323,c20918,c24225,c27259,c5399,c6,c9584           d5  g17,g29,g7  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "films_historiques\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3933492387.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\joans\\AppData\\Local\\Temp\\ipykernel_6516\\3933492387.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    def df_similarity(a,b){\u001b[0m\n\u001b[1;37m                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def df_similarity(a,b){\n",
    "        #a->datyaframe de films quon passe le filtre\n",
    "        #b->hidtorique de l'utilisateur\n",
    "        for i in a.\n",
    "                #calculer la similarité/correlation entre deux films\n",
    "    #calculer la similarité/correlation entre deux films\n",
    "        return similarity\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(df_a, df_b):\n",
    "    # Drop the id column from the b dataframe\n",
    "    df_b_no_id = df_b.drop('id_show', axis=1)\n",
    "    \n",
    "    # Convert the dataframes to numpy arrays\n",
    "    a_arr = df_a.drop('id_show', axis=1).values\n",
    "    b_arr = df_b_no_id.values\n",
    "    \n",
    "    # Calculate the cosine similarity matrix between the films in a and b\n",
    "    sim_matrix = cosine_similarity(a_arr, b_arr)\n",
    "    \n",
    "    # Sum the similarities across the rows to get the total similarity for each film in a\n",
    "    sim_sum = sim_matrix.sum(axis=1)\n",
    "    \n",
    "    # Create a new dataframe with the id column from a and the sum of similarities\n",
    "    result_df = pd.DataFrame({'id_show': df_a['id_show'], 'similarity_sum': sim_sum})\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(df_a, df_b):\n",
    "    # Drop the id column from the b dataframe\n",
    "    df_b_no_id = df_b.drop('id_show', axis=1)\n",
    "\n",
    "    # Calculate the cosine similarity matrix between the films in a and b\n",
    "    sim_matrix = cosine_similarity(df_a.drop('id_show', axis=1), df_b_no_id)\n",
    "\n",
    "    # Calculate the average similarity for each film in a\n",
    "    sim_avg = sim_matrix.mean(axis=1)\n",
    "\n",
    "    # Create a new dataframe with the id column from a and the average similarity\n",
    "    result_df = pd.DataFrame({'id_show': df_a['id_show'], 'similarity_avg': sim_avg})\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(df_a, df_b):\n",
    "    # Drop the id column from the b dataframe\n",
    "    df_b_no_id = df_b.drop('id_show', axis=1)\n",
    "\n",
    "    # Create a copy of df_a with the columns that can be used to calculate similarity\n",
    "    a_similarity = df_a[['id_show', 'year', 'description']].copy()\n",
    "    # For the columns that are lists of strings, join the strings into a single string\n",
    "    a_similarity['director_ids'] = df_a['director_ids'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "    a_similarity['cast_ids'] = df_a['cast_ids'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "    a_similarity['genre_ids'] = df_a['genre_ids'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "    a_similarity['country'] = df_a['country'].apply(lambda x: ' '.join(x.split(',')) if isinstance(x, str) else x)\n",
    "\n",
    "    # Create a copy of df_b with the columns that can be used to calculate similarity\n",
    "    b_similarity = df_b[['year', 'description']].copy()\n",
    "    # For the columns that are lists of strings, join the strings into a single string\n",
    "    b_similarity['director_ids'] = df_b['director_ids'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "    b_similarity['cast_ids'] = df_b['cast_ids'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "    b_similarity['genre_ids'] = df_b['genre_ids'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "    b_similarity['country'] = df_b['country'].apply(lambda x: ' '.join(x.split(',')) if isinstance(x, str) else x)\n",
    "\n",
    "    # Calculate the cosine similarity matrix between the films in a and b\n",
    "    sim_matrix = cosine_similarity(a_similarity.drop('id_show', axis=1), b_similarity)\n",
    "\n",
    "    # Calculate the average similarity for each film in a\n",
    "    sim_avg = sim_matrix.mean(axis=1)\n",
    "\n",
    "    # Create a new dataframe with the id column from a and the average similarity\n",
    "    result_df = pd.DataFrame({'id_show': df_a['id_show'], 'similarity_avg': sim_avg})\n",
    "\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for every film in the list of films that passed the manual filtering, get the correlation between the film and the films in the historial (1 for user) (4 max) (id)\n",
    "# faire la moyenne donc chaque user il aura un correspondance avec chaque film qui passe le filtre manuel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\joans\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\joans\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove stop words\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    filtered_text = [word for word in text.lower().split() if word not in stop_words]\n",
    "    \n",
    "    # Perform stemming\n",
    "    ps = PorterStemmer()\n",
    "    stemmed_text = [ps.stem(word) for word in filtered_text]\n",
    "    \n",
    "    # Perform lemmatization\n",
    "    lem = WordNetLemmatizer()\n",
    "    lemmatized_text = [lem.lemmatize(word, \"v\") for word in stemmed_text]\n",
    "    \n",
    "    return \" \".join(lemmatized_text)\n",
    "\n",
    "def calculate_similarity(df_a, df_b):\n",
    "    # Drop the id column from the b dataframe\n",
    "    df_b_no_id = df_b.drop('id_show', axis=1)\n",
    "\n",
    "    # Create a copy of df_a with the columns that can be used to calculate similarity\n",
    "    a_similarity = df_a[['id_show', 'year', 'description']].copy()\n",
    "    # For the columns that are lists of strings, join the strings into a single string\n",
    "    a_similarity['director_ids'] = df_a['director_ids'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "    a_similarity['cast_ids'] = df_a['cast_ids'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "    a_similarity['genre_ids'] = df_a['genre_ids'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "    a_similarity['country'] = df_a['country'].apply(lambda x: ' '.join(x.split(',')) if isinstance(x, str) else x)\n",
    "\n",
    "    # Create a copy of df_b with the columns that can be used to calculate similarity\n",
    "    b_similarity = df_b[['year', 'description']].copy()\n",
    "    # For the columns that are lists of strings, join the strings into a single string\n",
    "    b_similarity['director_ids'] = df_b['director_ids'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "    b_similarity['cast_ids'] = df_b['cast_ids'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "    b_similarity['genre_ids'] = df_b['genre_ids'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "    b_similarity['country'] = df_b['country'].apply(lambda x: ' '.join(x.split(',')) if isinstance(x, str) else x)\n",
    "\n",
    "    # Preprocess the description column\n",
    "    a_similarity['description'] = a_similarity['description'].apply(preprocess_text)\n",
    "    b_similarity['description'] = b_similarity['description'].apply(preprocess_text)\n",
    "\n",
    "    # Calculate the cosine similarity matrix between the films in a and b\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix_a = tfidf_vectorizer.fit_transform(a_similarity['description'])\n",
    "    tfidf_matrix_b = tfidf_vectorizer.transform(b_similarity['description'])\n",
    "    cosine_similarities = cosine_similarity(tfidf_matrix_a, tfidf_matrix_b)\n",
    "\n",
    "    # Create a dataframe to store the similarity scores\n",
    "    similarity_df = pd.DataFrame(cosine_similarities, columns=df_b['id_show'], index=df_a['id_show'])\n",
    "\n",
    "    return similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  id_show     type                              title         country  year  \\\n",
      "0   s1010    Movie    Rudra: Secret of the Black Moon                  2020   \n",
      "1    s812    Movie  Super Monsters: Once Upon a Rhyme                  2021   \n",
      "2      s9  TV Show      The Great British Baking Show  United Kingdom  2021   \n",
      "\n",
      "    duration                                        description  \\\n",
      "0     87 min  Kid magician Rudra sets out to save Earth from...   \n",
      "1     25 min  From Goldilocks to Hansel and Gretel, the Supe...   \n",
      "2  9 Seasons  A talented batch of amateur bakers face off in...   \n",
      "\n",
      "                                            cast_ids director_ids genre_ids  \n",
      "0  c10075,c17778,c21335,c23642,c24640,c27605,c321...   d4061,d595        g6  \n",
      "1  c10442,c1321,c1323,c17688,c2466,c2657,c30128,c...         d469        g6  \n",
      "2                               c1205,c5179,c5400,c7           d6    g15,g8  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joans\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py:762: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#TEST\n",
    "t=(\"s9\",\"s812\",\"s1010\",\"s333\")\n",
    "requete= \"SELECT show_new.*, GROUP_CONCAT(DISTINCT jouer.id_cast SEPARATOR ',') as cast_ids, GROUP_CONCAT(DISTINCT produire.id_direc SEPARATOR ',') as director_ids,GROUP_CONCAT(DISTINCT etre.id_genre SEPARATOR ',') as genre_ids FROM show_new LEFT JOIN jouer ON jouer.id_show = show_new.id_show LEFT JOIN produire ON produire.id_show = show_new.id_show LEFT JOIN etre ON etre.id_show = show_new.id_show  WHERE show_new.id_show IN {} GROUP BY show_new.id_show; \".format(t)\n",
    "films_filtres = pd.read_sql(requete, cnxn)\n",
    "print(films_filtres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>id_show</th>\n",
       "      <th>s10</th>\n",
       "      <th>s3</th>\n",
       "      <th>s8</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_show</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>s1010</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s812</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "id_show  s10   s3   s8\n",
       "id_show               \n",
       "s1010    0.0  0.0  0.0\n",
       "s812     0.0  0.0  0.0\n",
       "s9       0.0  0.0  0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "calculate_similarity(films_filtres, films_historiques)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
